\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amssymb,amsmath}
\usepackage[parfill]{parskip}
%\usepackage[margin=1in]{geometry}
\title{Optimization 10/36-725\\
        Homework 1}
\author{}
\date{}
\begin{document}
\maketitle


\section{Problem One}

\subsection{A1}
For $k=2$, from the definition of convexity, we know $x_1,x_2 \in C \implies
\theta_1 x_1 + \theta_2 x_2 \in C$,  for all $\theta_1,\theta_2>0$,
$\theta_1+\theta_2 = 1$.

We will prove this for all $k$ via induction. Suppose, for a given $k$, 
\begin{equation}
    \sum_{i=1}^k \theta_i x_i  \in C
\end{equation}
Then, for $k+1$, 
\begin{align}
    \sum_{i=1}^{k+1} \theta_i x_i  &= \left( \sum_{i=1}^k \theta_i x_i
  \right) + \theta_{k+1}x_{k+1} \\ &= (1-\theta_{k+1}) \left( \sum_{i=1}^k
    \frac{\theta_i}{(1-\theta_{k+1})} x_i \right) + \theta_{k+1}x_{k+1}
\end{align}
Define $\tilde{x} := \sum_{i=1}^k \frac{\theta_i}{(1-\theta_{k+1})} x_i$ And
note that
\begin{align}
    \sum_{i=1}^k \frac{\theta_i}{(1-\theta_{k+1})} = \frac{\sum_{i=1}^k
    \theta_i}{(1-\theta_{k+1})} = \frac{\sum_{i=1}^k \theta_i}{\sum_{i=1}^k
    \theta_i} = 1
\end{align}
So therefore, $\tilde{x}$ satisfies the induction hypothesis (using coefficients
$\frac{\theta_i}{(1-\theta_{k+1})}$, $i=1,\ldots,k$) and hence $\tilde{x} \in C$. Therefore,
\begin{align}
    \sum_{i=1}^{k+1} \theta_i x_i &= (1-\theta_{k+1}) \left( \sum_{i=1}^k
    \frac{\theta_i}{(1-\theta_{k+1})} x_i \right) + \theta_{k+1}x_{k+1} \\ &=
    (1-\theta_{k+1}) \tilde{x} + \theta_{k+1}x_{k+1} \in C
\end{align}
Note that the last term is in $C$ from the definition of convexity, since $\tilde{x}$ and
$x_{k+1}$ $\in C$, and $(1-\theta_{k+1}) + \theta_{k+1} = 1$.  Hence
$\sum_{i=1}^{k+1} \theta_i x_i \in C$, and the result holds for all $k \geq 1$.


\subsection{A2}
First, we'll show $conv_2(M) \subset conv_1(M)$:\\ We will suppose not and find
a contradiction. If we suppose not, then there exists a convex set containing
$M$ that does not completely contain the convex hull of $M$ (i.e. there exist
some convex combinations of points in $M$ that are not some other convex set
containing $M$). But this contradicts what we showed in part \textbf{A1},
namely that for a set of points in a convex set $C$, any convex combination of
these points will also be in $C$. Hence, it must be that $conv_2(M) \subset
conv_1(M)$.

%Next, we'll show $conv_1(M) \subset conv_2(M)$:\\ Again, we will suppose not
%and find a contradiction. If we suppose not, then there exists some element $x$
%that is in all convex sets containing $M$, and yet is not in the convex hull of
%$M$ (i.e. $x$ does not equal some convex combination of the points in $M$). But
%the convex hull of $M$ is convex and contains $M$.  Since this convex set does
%not contain $x$, we have a contradiction. Therefore, $conv_1(M) \subset
%conv_2(M)$.\\
Next, we'll show $conv_1(M) \subset conv_2(M)$:\\
If $x \in conv_1(M)$, then it is in all convex sets containing $M$ (as it is in
the intersection), including $conv_2(M)$ (which we know is convex). Hence 
$x \in conv_2(M)$ and $conv_1(M) \subset conv_2(M)$.


\subsection{B1}
For any two points $x_1$ and $x_2$ $\in HP(a,b)$, consider $x_3 = \theta x_1 +
(1-\theta) x_2$ (where $\theta \in [0,1]$). Then
\begin{align}
    a^{\top} x_3 = a^{\top} (\theta x_1 + (1-\theta) x_2) = \theta a^{\top} x_1
    + (1-\theta) a^{\top} x_2 = \theta b + (1-\theta) b = b
\end{align}
Hence $x_3 \in HP(a,b)$, and $HP(a,b)$ is a convex set.

Also, the distance between parallel hyperplanes $HP(a,b_1)$ and $HP(a,b_2)$ is
$\frac{| b_1 - b_2 |}{\|a \|}$.


\subsection{B2}
For any two points $x_1$ and $x_2$ $\in HS(a,b)$, consider $x_3 = \theta x_1 +
(1-\theta) x_2$ (where $\theta \in [0,1]$). Then
\begin{align}
    a^{\top} x_3 = a^{\top} (\theta x_1 + (1-\theta) x_2) = \theta a^{\top} x_1
    + (1-\theta) a^{\top} x_2 \leq \theta b + (1-\theta) b \leq b
\end{align}
Hence $x_3 \in HS(a,b)$, and $HS(a,b)$ is a convex set. Additionally, if $a_1 = a_2$, 
and $b_2 \leq b_1$, then all points in $HS(a_2,b_2)$ are in $HS(a_1,b_1)$ and thus 
$HS(a_2,b_2) \subset HS(a_1,b_1)$.

\subsection{B3}
The set of points closer to $u$ than $v$ are the points $x$ such that
\begin{align}
    \|x-u\| \leq \|x-v\|  \hspace{2mm}\text{ i.e. such that }\\
    (x-u)^{\top}(x-u) \leq (x-v)^{\top}(x-v) \hspace{2mm}\text{ i.e. such that }\\
    x^{\top}x - 2 u^{\top} x + u^{\top}u \leq x^{\top}x - 2 v^{\top} x +
    v^{\top}v  \hspace{2mm}\text{ i.e. such that }\\
    2(v-u)^{\top} x \leq v^{\top}v - u^{\top}u \hspace{2mm}\text{ i.e. such
    that }\\
\end{align}
which meets the previously given definition of a halfspace, taking $a = (2v - 2u)^{\top}$ and 
$b = v^{\top}v - u^{\top}u$, which means that this set of points is also a convex set (given
our proof in (B2)).

\subsection{C}
The function $f$ is s.t. $\forall x_1,x_2 \in \mathbb{R}_+$ and $\theta \in [0,1]$
\begin{align}
    f(\theta x_1 + (1-\theta)x_2) \leq \theta f(x_1) + (1-\theta) f(x_2)
\end{align}
And hence for all $s>0$, the function $f(sx)$ has the property that
\begin{align}
    f(s (\theta  x_1 + (1-\theta) x_2)) = f( \theta s  x_1 + (1-\theta) s  x_2)
    \leq \theta f(s x_1) + (1-\theta) f(s x_2)
\end{align}
and hence $f(sx)$ is convex. Additionally, since convexity holds under sums
(and under integrals), $\int_0^1 f(sx) ds$ is also convex, and $\int_0^1 f(sx)
ds = \frac{1}{x} \int_0^x f(u) du$ (using the substitution $u=sx$). Hence,
$\frac{1}{x} \int_0^x f(u) du$ is also a convex function.


\subsection{D}
Converting this LP to standard form, we have
\begin{align}
    -\left( \min_{a_1,\ldots,a_6} c^{\top} \begin{pmatrix}a_1\\ \vdots\\ a_6\end{pmatrix}  + 2  \right)
\end{align}
such that $c = [-3,1,-1,1,0,0]$, $a_1= x+1$, $a_2 = y+1$, $a_3-a_4=z$, $a_1 + a_5 = 2$, $a_2 + a_6 = 2$,
and $a_i \geq 0$ (for all $i=1,\ldots,6$). Further, via inspection, we can see
that the optimal value of $5$ is obtained when $x=1$, $y=-1$, and $z=1$.

\end{document}
